\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[final,pagenumbers]{assets/cvpr}

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}

\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}

\begin{document}

\title{Comparative Analysis of Class introduced and External Methods for Classification}

\author{Evan Donovan\\
  Boston University\\
  {\tt\small donovan@bu.edu}
  \and
  Mitchell Gilmore\\
  Boston University\\
  {\tt\small mgilm0re@bu.edu}
  \and
  William Harrington\\
  Boston University\\
  {\tt\small harriw5@bu.edu}
}
\maketitle

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:intro}

Given the broad set of algorithms and methods for machine learning and analytics, there is value in understanding and interpreting the variation between different data science models.
The purpose of this study will be to analyze the effectiveness of distinct algorithm types on structured, tabular data.
This comparison of algorithms will focus on variation in loss during testing and variation in loss between test runs.

Our team plans to implement fully developed algorithms for five types of classification models: Linear Discriminant Analysis (LDA), Logistic Regression, Gradient Boosting, Random Forest, and Naive Bayesian.
This will require significant time spent learning the methods, developing the algorithm structure, training the model, running validation checks for correct implementation and debugging based on errors before implementing on test data.
Given the extensive labor involved in accomplishing all these tasks, we will also identify available repositories for implementing these algorithms readily for those that we are unable to develop in a timely manner.

Three of the selected classifier tools are methods that were not covered in class, so there is background, research, and theory that must be reviewed in order to qualitatively analyze each model’s effectiveness.
The new methods are all similar in that the algorithms work most effectively on structured, tabular data, so we will focus on gathering formatted data which we can provide directly to the models with minimal pre-processing.
Each method will be discussed and assessed based on the same training and test data which will serve as controls on the implementation and should standardize the results for comparison.
Additionally, each member of the team will gain a deep understanding of one of the chosen methods independently and provide this insight to the team during the comparative analysis.

\section{Literature Review}
\label{sec:related}

Three of the five models we will be implementing are not covered in class.
Therefore, in addition to implementing the models, we will also be reviewing the literature on the methods to gain a deeper understanding of the models and their applications.
This is vital for implementing the models correctly, explaining the methods in the report, giving intuition for the results, and explaining the algorithms in the presentation.

\subsection{Gradient Boosting}

Gradient boosting is a machine learning technique, first introduced in 1999 by Jerome H. Friedman \cite{gradientboosting} that builds an ensemble of predictive models, typically decision trees, in a sequential manner.
Each new tree aims to correct the errors of the preceding ones.
The algorithm learns by fitting subsequent trees to the residual errors of the combined ensemble of existing trees.
This iterative correction process often results in high accuracy with appropriate tuning.

In contrast, random forests also build ensembles of decision trees but do so in parallel.
Each tree in a random forest is trained independently, using a bootstrap sample of the data and a random subset of features.
This randomness introduces diversity among the trees, helping the ensemble to reduce variance without increasing bias.

Gradient boosting machines though an older machine learning technique have shown in practical applications to be one of the best models for tabular data winning many Kaggle data science competitions.
The success is so wide reaching that the CEO of Kaggle has noted its wide success in its competitions, specifically the XGBoost \cite{xgboost} python library during an interview in the weights and biases podcast \cite{kaggle}.

\subsection{Random Forests}

The original Random Forest methodology was developed by Leo Breiman in his paper, “Random Forests”, in 2001 \cite{randomforest}.
It provides an understanding of the classification method of developing tree structures and the effective convergence of “randomly” selected partitions.
Particularly, it notes the improvements in comparison to other contemporary methods, particularly in data estimation and computational intensity.

Gerard Biau and Erwan Scornet provide “A Random Forest Guided Tour” for understanding the theory, intuitive process and implementation practices for the Random Forest methodology \cite{randomforesttour}.
While this paper focuses on the regression method, the paper facilitates understanding the classification method.
The key parameters that impact results of the random forest algorithm are the selected sample points, the directionality of node splitting and the leaf size.

These parameters effectively allow the data set to be divided into smaller and smaller subsets until a final tree structure is developed.
In a regression model, this would lead to a linear model, but the classification model can be similarly developed by varying the final leaf sizes and determining the lowest loss structure in the training set.

\subsection{Naive Bayes}

The Naive Bayesian classification is a probabilistic classification model that leverages prior conditional probabilities of features while assuming all probabilities to be mutually independent - hence the “naive” in its name.
Despite its simplicity, it has been found to perform well \cite{domingos,webb}. 

The algorithm works by first training on a labeled dataset to estimate the conditional probabilities of each feature given each class.
In order to formulate class predictions, it finds the probability of each instance belonging to each class and classifies based on an objective function.
Typically this objective function is either the argmax of the probability or minimizing the probability of misclassification.
The simplicity and speed of the Naive Bayes classifier make it particularly suitable for text classification tasks.
However, due to its “naivety,” it will struggle on datasets when the independence assumption is strongly violated in the data (such as medical diagnoses), and it’s not well-suited for complex relationships in high-dimensional data.

\section{Datasets}

The datasets are still being explored, but we have identified a few potential datasets that we will use for our analysis.
We are restricting out scope to tabular data that is structured and formatted for direct input to the models.
For easy reproducibility, we will use the same datasets for each model and look for datasets that are publicly available and have been used in other studies.
Due to ubiquity and it easy automation we will use Kaggle as the main resource to compile the datasets.
For good variety we will use datasets from different domains and will choose between 6 and 10 datasets for comparison.

\section{Division of Labor}

In this section we will outline the division of labor for the project.
Each team member will be responsible for implementing one/two of the five models.
Additionally one member will be responsible for data collection and sanitizing it for use in the models.
All members have collectively agreed on this division of labor and have agreed to help each other as needed.
Additionally anything that falls out of the points mentioned here will be handled by the team as a whole.

\subsection{Evan Donovan}
\begin{enumerate}
  \item Gradient Boosting
  \item Logistic Regression
\end{enumerate}

\subsection{Mitchell Gilmore}
\begin{enumerate}
  \item Random Forest
  \item Linear Discriminant Analysis
\end{enumerate}

\subsection{William Harrington}
\begin{enumerate}
  \item Naive Bayes
  \item Data Collection
\end{enumerate}

{
  \small
  \bibliographystyle{assets/ieee_fullname}
  \bibliography{assets/Project}
}

\end{document}
